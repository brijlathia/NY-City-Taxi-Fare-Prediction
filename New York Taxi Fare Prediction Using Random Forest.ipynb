{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2229.689437150955 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import time \n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "PATH = r\"C:\\Users\\Rj\\train.csv\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "sample_cols_to_keep =['fare_amount','pickup_datetime','pickup_longitude','pickup_latitude',\n",
    "                      'dropoff_longitude','dropoff_latitude','passenger_count']\n",
    "\n",
    "# First setup dataframe iterator, ‘usecols’ parameter filters the columns, and 'chunksize' \n",
    "# sets the number of rows per chunk in the csv.\n",
    "# we are not using 10M rows out of 55M rows for faster execution\n",
    "df_iter = pd.read_csv(PATH, chunksize=100000, usecols=sample_cols_to_keep,nrows= 10000000)\n",
    "\n",
    "# haversine formulate to calculate total distance between two points on earth.\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    lat1 = np.radians(lat1)\n",
    "    lat2= np.radians(lat2)\n",
    "    lon1 = np.radians(lon1)\n",
    "    lon2 = np.radians(lon2)\n",
    "    dlat=(lat2-lat1).abs()\n",
    "    dlon=(lon2-lon1).abs()\n",
    "    R = 6371 #radius of Earth\n",
    "    a = (np.sin(dlat/2.0))**2 + np.cos(lat1) * np.cos(lat2) * (np.sin(dlon/2.0))**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "# removing timestamp dtype from data and featching and seperating useful data from that\n",
    "# using new features in the predictive model for better prediction\n",
    "def add_features(df):\n",
    "    df['Distance_Travelled'] = haversine(df.dropoff_longitude,df.dropoff_latitude,df.pickup_longitude,df.pickup_latitude)\n",
    "    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "    df['hour'] = df.pickup_datetime.dt.hour\n",
    "    df['day'] = df.pickup_datetime.dt.day\n",
    "    df['month'] = df.pickup_datetime.dt.month\n",
    "    df['weekday'] = df.pickup_datetime.dt.weekday\n",
    "    df['year'] = df.pickup_datetime.dt.year \n",
    "    \n",
    "# this list will store the filtered dataframes for later concatenation \n",
    "df_lst = [] \n",
    "\n",
    "# Iterate over the file based on the criteria and append to the list\n",
    "# And removing useless data\n",
    "for df_ in df_iter: \n",
    "        tmp_df = (df_.rename(columns={col: col.lower() for col in df_.columns}) # filter eg. rows where 'col_1' value grater than one\n",
    "                                  .pipe(lambda x:  x[x.passenger_count > 0])\n",
    "                                  .pipe(lambda x:  x[x.fare_amount > 1])\n",
    "                                  .pipe(lambda x:  x[x.fare_amount < 500])\n",
    "                                  .pipe(lambda x:  x[x.passenger_count < 6])\n",
    "                                  .pipe(lambda x:  x[x.pickup_longitude < -72])\n",
    "                                  .pipe(lambda x:  x[x.pickup_longitude > -75])\n",
    "                                  .pipe(lambda x:  x[x.pickup_latitude > 40.2])\n",
    "                                  .pipe(lambda x:  x[x.pickup_latitude < 42 ]) \n",
    "                                  .pipe(lambda x:  x[x.dropoff_longitude < -72])\n",
    "                                  .pipe(lambda x:  x[x.dropoff_longitude > -75])\n",
    "                                  .pipe(lambda x:  x[x.dropoff_latitude > 40])\n",
    "                                  .pipe(lambda x:  x[x.dropoff_latitude < 42 ]))\n",
    "        add_features(tmp_df)      \n",
    "        df_lst += [tmp_df.copy()] \n",
    "                                     \n",
    "print('%s seconds' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9546017, 13)\n"
     ]
    }
   ],
   "source": [
    "# And finally combine filtered df_lst into the final lareger output say 'df_final' dataframe \n",
    "df_final = pd.concat(df_lst)\n",
    "# df_final.describe()\n",
    "print(df_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.513366937637329 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "test_df = pd.read_csv(r\"C:\\Users\\Rj\\test.csv\")\n",
    "# Also adding more features to test data\n",
    "add_features(test_df)\n",
    "\n",
    "print('%s seconds' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rows with null values and removing column with timestamp dtype which is no longer needed.\n",
    "df_final.dropna(how = 'any', axis = 'rows', inplace=True)\n",
    "df_final.drop(['pickup_datetime'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# creating feature matrix and label vector\n",
    "X = df_final[['pickup_longitude','pickup_latitude',\n",
    "              'dropoff_longitude','dropoff_latitude','passenger_count'\n",
    "             ,'Distance_Travelled','hour','day','month','weekday','year']]\n",
    "y=  df_final['fare_amount']\n",
    "X =preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.087108373641968 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "# Randomly splitting the original dataset into training set and testing set\n",
    "# \"test_size=0.25\" means that pick 30% of data samples for testing set, and the rest (75%) for training set.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "print('%s seconds' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4541.521301984787 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Importing the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 30 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 30,bootstrap = True, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train);\n",
    "print('%s seconds' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.6322588837543093\n",
      "Mean Squared Error: 13.676028679634898\n",
      "Root Mean Squared Error: 3.6981115017850525\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Testing on the testing set:\n",
    "rf_pred= rf.predict(X_test)\n",
    "\n",
    "# Calculating MAE MSE RMSE values \n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, rf_pred))\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "# mape = 100 * (metrics.mean_absolute_error(y_test, rf_pred)/ y_test)\n",
    "# Calculate and display accuracy\n",
    "# accuracy = 100 - np.mean(mape)\n",
    "# print('Accuracy:', round(accuracy, 2), '%.')\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, rf_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, rf_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.18 %.\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (metrics.mean_absolute_error(y_test, rf_pred)/ y_test)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting on Test cvs data and keeping same feature as feature matrix\n",
    "rf_pred= rf.predict(test_df.drop(['key','pickup_datetime'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Creating a dataframe for our prediction and then saving it to a cvs file\n",
    "result = pd.DataFrame({\"key\":test_df[\"key\"], \"fare_amount\": rf_pred},\n",
    "                         columns = ['key', 'fare_amount'])\n",
    "result.to_csv (r\"C:\\Users\\Rj\\fare.csv\", index = False, header=True) \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.18065718512594\n"
     ]
    }
   ],
   "source": [
    "# checking the mean of fare_amount to check the correctness of the model\n",
    "# more the rows we train, model will be more accurate\n",
    "df = pd.read_csv(r\"C:\\Users\\Rj\\fare.csv\")\n",
    "mean = df['fare_amount'].mean()\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
